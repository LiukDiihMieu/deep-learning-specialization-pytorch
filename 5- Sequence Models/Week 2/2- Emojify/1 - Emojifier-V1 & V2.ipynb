{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "## imports and configuration\n",
    "import numpy as np\n",
    "from emo_utils import *\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "torch.set_printoptions(linewidth=200)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Baseline model: Emojifier-V1\n",
    "\n",
    "### 1.1 - Dataset EMOJISET\n",
    "\n",
    "Let's start by building a simple baseline classifier. \n",
    "\n",
    "You have a tiny dataset (X, Y) where:\n",
    "- X contains 127 sentences (strings)\n",
    "- Y contains a integer label between 0 and 4 corresponding to an emoji for each sentence\n",
    "\n",
    "<img src=\"images/data_set.png\" style=\"width:700px;height:300px;\">\n",
    "<caption><center> **Figure 1**: EMOJISET - a classification problem with 5 classes. A few examples of sentences are given here. </center></caption>\n",
    "\n",
    "Let's load the dataset using the code below. We split the dataset between training (127 examples) and testing (56 examples)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLen = len(max(X_train, key=len).split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to print sentences from X_train and corresponding labels from Y_train. Change `index` to see different examples. Because of the font the iPython notebook uses, the heart emoji may be colored black rather than red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am proud of your achievements üòÑ\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "print(X_train[index], label_to_emoji(Y_train[index]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Overview of the Emojifier-V1\n",
    "\n",
    "In this part, you are going to implement a baseline model called \"Emojifier-v1\".  \n",
    "\n",
    "<center>\n",
    "<img src=\"images/image_1.png\" style=\"width:900px;height:300px;\">\n",
    "<caption><center> **Figure 2**: Baseline model (Emojifier-V1).</center></caption>\n",
    "</center>\n",
    "\n",
    "The input of the model is a string corresponding to a sentence (e.g. \"I love you\"). In the code, the output will be a probability vector of shape (1,5), that you then pass in an argmax layer to extract the index of the most likely emoji output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get our labels into a format suitable for training a softmax classifier, lets convert $Y$ from its current shape  current shape $(m, 1)$ into a \"one-hot representation\" $(m, 5)$, where each row is a one-hot vector giving the label of one example, You can do so using this next code snipper. Here, `Y_oh` stands for \"Y-one-hot\" in the variable names `Y_oh_train` and `Y_oh_test`: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_oh_train = convert_to_one_hot(Y_train, C = 5)\n",
    "Y_oh_test = convert_to_one_hot(Y_test, C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 is converted into one hot [1. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "index = 50\n",
    "print(Y_train[index], \"is converted into one hot\", Y_oh_train[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the data is now ready to be fed into the Emojify-V2 model. Let's implement the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 - Implementing Emojifier-V1\n",
    "\n",
    "As shown in Figure (2), the first step is to convert an input sentence into the word vector representation, which then get averaged together. Similar to the previous exercise, we will use pretrained 50-dimensional GloVe embeddings. Run the following cell to load the `word_to_vec_map`, which contains all the vector representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs('data/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've loaded:\n",
    "- `word_to_index`: dictionary mapping from words to their indices in the vocabulary (400,001 words, with the valid indices ranging from 0 to 400,000)\n",
    "- `index_to_word`: dictionary mapping from indices to their corresponding words in the vocabulary\n",
    "- `word_to_vec_map`: dictionary mapping words to their GloVe vector representation.\n",
    "\n",
    "Run the following cell to check if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index of cucumber in the vocabulary is 113317\n",
      "the 289846th word in the vocabulary is potatos\n"
     ]
    }
   ],
   "source": [
    "word = \"cucumber\"\n",
    "index = 289846\n",
    "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
    "print(\"the\", str(index) + \"th word in the vocabulary is\", index_to_word[index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: Implement `sentence_to_avg()`. You will need to carry out two steps:\n",
    "1. Convert every sentence to lower-case, then split the sentence into a list of words. `X.lower()` and `X.split()` might be useful. \n",
    "2. For each word in the sentence, access its GloVe representation. Then, average all these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    words = sentence.lower().split()\n",
    "    vectors = [torch.tensor(word_to_vec_map[word], dtype=torch.float32) for word in words]\n",
    "    vectors = torch.stack(vectors, axis=1)\n",
    "    return vectors.mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Emo_Dataset(Dataset):\n",
    "    def __init__(self, X, Y, word_to_vec_map):\n",
    "        self.word_to_vec_map = word_to_vec_map\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        super().__init__()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = sentence_to_avg(self.X[index], word_to_vec_map)\n",
    "        y = self.Y[index]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "trn_ds = Emo_Dataset(X_train, Y_train, word_to_vec_map)\n",
    "trn_dl = DataLoader(trn_ds, batch_size=batch_size, shuffle=True)\n",
    "test_ds = Emo_Dataset(X_test, Y_test, word_to_vec_map)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model\n",
    "\n",
    "You now have all the pieces to finish implementing the `model()` function.\n",
    "\n",
    "**Exercise**: Implement the `model()` function described in Figure (2). Assuming here that $Yoh$ (\"Y one hot\") is the one-hot encoding of the output labels, the equations you need to implement in the forward pass and to compute the cross-entropy cost are:\n",
    "$$ z^{(i)} = W . avg^{(i)} + b$$\n",
    "$$ a^{(i)} = softmax(z^{(i)})$$\n",
    "$$ \\mathcal{L}^{(i)} = - \\sum_{k = 0}^{n_y - 1} Yoh^{(i)}_k * log(a^{(i)}_k)$$\n",
    "\n",
    "It is possible to come up with a more efficient vectorized implementation. But since we are using a for-loop to convert the sentences one at a time into the avg^{(i)} representation anyway, let's not bother this time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(in_features=50, out_features=5).to(device)\n",
    "nn.init.xavier_uniform_(model.weight)  # Initialize parameters using Xavier initialization\n",
    "loss_fn = nn.CrossEntropyLoss()  # already contains softmax in CrossEntropyLoss\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dl):\n",
    "    model.eval()\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            z = model(x)\n",
    "            pred_cls = torch.softmax(z, dim=1).argmax(dim=1)\n",
    "            correct_preds += (y == pred_cls).sum().item()\n",
    "            total_preds += y.shape[0]\n",
    "    model.train()\n",
    "    return correct_preds / total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, trn_dl, num_epochs=400):\n",
    "    model.train()\n",
    "    for e in range(num_epochs):\n",
    "        for x, y in trn_dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            z = model(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if e % 100 == 0:\n",
    "            print(f'Epoch: {e} --- cost = {loss}')\n",
    "            accuracy = compute_accuracy(model, trn_dl)\n",
    "            print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = 2.171079158782959\n",
      "Accuracy: 0.2727272727272727\n",
      "Epoch: 100 --- cost = 1.025998592376709\n",
      "Accuracy: 0.7272727272727273\n",
      "Epoch: 200 --- cost = 0.655185341835022\n",
      "Accuracy: 0.8333333333333334\n",
      "Epoch: 300 --- cost = 0.6623440384864807\n",
      "Accuracy: 0.8409090909090909\n"
     ]
    }
   ],
   "source": [
    "train(model, loss_fn, optimizer, trn_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Your model has pretty high accuracy on the training set. Lets now see how it does on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.8863636363636364\n",
      "Test set accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set accuracy:\", compute_accuracy(model, trn_dl))\n",
    "print(\"Test set accuracy:\", compute_accuracy(model, test_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random guessing would have had 20% accuracy given that there are 5 classes. This is pretty good performance after training on only 127 examples. \n",
    "\n",
    "In the training set, the algorithm saw the sentence \"*I love you*\" with the label ‚ù§Ô∏è. You can check however that the word \"adore\" does not appear in the training set. Nonetheless, lets see what happens if you write \"*I adore you*.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_custom_sentences(model, sentences, labels, word_to_vec_map):\n",
    "    model.eval()\n",
    "    num_examples = len(sentences)\n",
    "    correct_preds = 0\n",
    "    y = torch.tensor(labels).to(device)\n",
    "    with torch.no_grad():\n",
    "        for (sentence, label) in zip(sentences, y):\n",
    "            x = sentence_to_avg(sentence, word_to_vec_map).to(device)\n",
    "            z = model(x)\n",
    "            pred_cls = torch.softmax(z, dim=-1).argmax()\n",
    "            correct_preds += (label == pred_cls).item()\n",
    "            print(sentence, label_to_emoji(pred_cls.item()))\n",
    "    \n",
    "    \n",
    "    print('\\nAccuracy:', correct_preds/num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_my_sentences = [\"you are a cute dog\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"]\n",
    "Y_my_labels = [0, 0, 2, 1, 4, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are a cute dog ‚ù§Ô∏è\n",
      "i love you ‚ù§Ô∏è\n",
      "funny lol üòÑ\n",
      "lets play with a ball ‚öæ\n",
      "food is ready üç¥\n",
      "not feeling happy üòÑ\n",
      "\n",
      "Accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "test_custom_sentences(model, X_my_sentences, Y_my_labels, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Emojifier-V2: Using LSTMs in PyTorch: \n",
    "\n",
    "Let's build an LSTM model that takes as input word sequences. This model will be able to take word ordering into account. Emojifier-V2 will continue to use pre-trained word embeddings to represent words, but will feed them into an LSTM, whose job it is to predict the most appropriate emoji. \n",
    "\n",
    "Run the following cell to load the PyTorch packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Overview of the model\n",
    "\n",
    "Here is the Emojifier-v2 you will implement:\n",
    "\n",
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center> **Figure 3**: Emojifier-V2. A 2-layer LSTM sequence classifier. </center></caption>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 PyTorch and mini-batching \n",
    "\n",
    "In this exercise, we want to train our model using mini-batches. However, most deep learning frameworks require that all sequences in the same mini-batch have the same length. This is what allows vectorization to work: If you had a 3-word sentence and a 4-word sentence, then the computations needed for them are different (one takes 3 steps of an LSTM, one takes 4 steps) so it's just not possible to do them both at the same time.\n",
    "\n",
    "The common solution to this is to use padding. Specifically, set a maximum sequence length, and pad all sequences to the same length. For example, of the maximum sequence length is 20, we could pad every sentence with \"0\"s so that each input sentence is of length 20. Thus, a sentence \"i love you\" would be represented as $(e_{i}, e_{love}, e_{you}, \\vec{0}, \\vec{0}, \\ldots, \\vec{0})$. In this example, any sentences longer than 20 words would have to be truncated. One simple way to choose the maximum sequence length is to just pick the length of the longest sentence in the training set. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_padding(sentence, word_to_vec_map, max_len):\n",
    "    # Split sentence into words and lowercase\n",
    "    words = sentence.lower().split()\n",
    "\n",
    "    # Convert words to vectors\n",
    "    vectors = [torch.tensor(word_to_vec_map[word], dtype=torch.float32) for word in words]\n",
    "\n",
    "    # Check if the number of words is less than the max length\n",
    "    if len(vectors) < max_len:\n",
    "        # Pad with zero vectors\n",
    "        pad_size = max_len - len(vectors)\n",
    "        vectors += [torch.zeros(50, dtype=torch.float32) for _ in range(pad_size)]\n",
    "    else:\n",
    "        # Truncate the vectors to max_len\n",
    "        vectors = vectors[:max_len]\n",
    "\n",
    "    # Stack vectors along the second dimension, transpose to match pytorch LSTM\n",
    "    vectors = torch.stack(vectors, dim=1).transpose(0, 1)\n",
    "\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emo_Dataset_V2(Dataset):\n",
    "    def __init__(self, X, Y, word_to_vec_map, max_len):\n",
    "        self.word_to_vec_map = word_to_vec_map\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.max_len = max_len\n",
    "        super().__init__()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = sentence_padding(self.X[index], word_to_vec_map, self.max_len)\n",
    "        y = self.Y[index]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Building the Emojifier-V2\n",
    "\n",
    "Lets now build the Emojifier-V2 model. You will do so using the embedding layer you have built, and feed its output to an LSTM network. \n",
    "\n",
    "<img src=\"images/emojifier-v2.png\" style=\"width:700px;height:400px;\"> <br>\n",
    "<caption><center> **Figure 3**: Emojifier-v2. A 2-layer LSTM sequence classifier. </center></caption>\n",
    "\n",
    "\n",
    "**Exercise:** Implement `Emojify_V2()`, which builds a Keras graph of the architecture shown in Figure 3. The model takes as input an array of sentences of shape (`m`, `max_len`, ) defined by `input_shape`. It should output a softmax probability vector of shape (`m`, `C = 5`). You may need `Input(shape = ..., dtype = '...')`, [LSTM()](https://keras.io/layers/recurrent/#lstm), [Dropout()](https://keras.io/layers/core/#dropout), [Dense()](https://keras.io/layers/core/#dense), and [Activation()](https://keras.io/activations/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(LSTMModel, self).__init__()\n",
    "\n",
    "        # Define the LSTM layer with dropout\n",
    "        self.lstm = nn.LSTM(input_size=embedding_dim,\n",
    "                            hidden_size=hidden_dim,\n",
    "                            num_layers=num_layers,\n",
    "                            batch_first=True,\n",
    "                            dropout=0.5)  # Dropout between LSTM layers\n",
    "\n",
    "        # Define a dropout layer for applying after LSTM\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # Define the final, fully-connected (linear) layer\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        # Apply Xavier Uniform initialization to LSTM weights\n",
    "        # This is to match the original Keras implementation\n",
    "        for name, param in self.lstm.named_parameters():\n",
    "            if 'weight_ih' in name:  # Input-hidden weights\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'weight_hh' in name:  # Hidden-hidden weights\n",
    "                nn.init.xavier_uniform_(param)\n",
    "            elif 'bias' in name:  # Biases\n",
    "                nn.init.zeros_(param)\n",
    "\n",
    "        # Apply Xavier Uniform initialization to the fully connected layer\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, seq_len, embedding_dim]\n",
    "\n",
    "        # LSTM\n",
    "        lstm_out, (hn, cn) = self.lstm(x)\n",
    "\n",
    "        # Only take the output from the final timestep\n",
    "        last_timestep_out = lstm_out[:, -1, :]\n",
    "\n",
    "        # Dropout after LSTM\n",
    "        out = self.dropout(last_timestep_out)\n",
    "\n",
    "        # Fully-connected layer\n",
    "        out = self.fc(out)\n",
    "\n",
    "        # No need to add softmax here as it is implemented in CrossEntropyLoss\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "embedding_dim = 50  # Dimension of word embeddings\n",
    "hidden_dim = 128    # LSTM output size\n",
    "output_dim = 5      # Final output size (number of classes)\n",
    "num_layers = 2      # Number of LSTM layers\n",
    "loss_fn = nn.CrossEntropyLoss()  # already contains softmax in CrossEntropyLoss\n",
    "\n",
    "# Model instance\n",
    "model = LSTMModel(embedding_dim, hidden_dim, output_dim, num_layers).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "trn_ds = Emo_Dataset_V2(X_train, Y_train, word_to_vec_map, 10)\n",
    "trn_dl = DataLoader(trn_ds, batch_size=batch_size, shuffle=True)\n",
    "test_ds = Emo_Dataset_V2(X_test, Y_test, word_to_vec_map, 10)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, dl):\n",
    "    model.eval()\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            z = model(x)\n",
    "            pred_cls = torch.softmax(z, dim=1).argmax(dim=1)\n",
    "            correct_preds += (y == pred_cls).sum().item()\n",
    "            total_preds += y.shape[0]\n",
    "    model.train()\n",
    "    return correct_preds / total_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, trn_dl, num_epochs=50):\n",
    "    model.train()\n",
    "    for e in range(num_epochs):\n",
    "        for x, y in trn_dl:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            z = model(x)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_fn(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if e % 20 == 0:\n",
    "            print(f'Epoch: {e} --- cost = {loss}')\n",
    "            accuracy = compute_accuracy(model, trn_dl)\n",
    "            print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = 1.5565693378448486\n",
      "Accuracy: 0.3333333333333333\n",
      "Epoch: 20 --- cost = 0.4079158306121826\n",
      "Accuracy: 0.8560606060606061\n",
      "Epoch: 40 --- cost = 0.04211046174168587\n",
      "Accuracy: 0.946969696969697\n"
     ]
    }
   ],
   "source": [
    "train(model, loss_fn, optimizer, trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy: 0.9924242424242424\n",
      "Test set accuracy: 0.8392857142857143\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set accuracy:\", compute_accuracy(model, trn_dl))\n",
    "print(\"Test set accuracy:\", compute_accuracy(model, test_dl))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
